# Originium-Python

## Structure

Modified from https://github.com/hardefarogonondo/data-science-project-folder-structure
    
```
ðŸ“¦ 
â”œâ”€ .gitignore
â”œâ”€ README.md                                # The top-level README for developers using this project
â”œâ”€ app.py                                   # Streamlit app
â”œâ”€ data                                     # Data directory
â”‚  â”œâ”€ processed                             # Processed data for model training and visualization
â”‚  â”‚  â”œâ”€ affiliations.csv                   # Affiliations data
â”‚  â”‚  â”œâ”€ author_pub_counts.csv              # Author publication counts
â”‚  â”‚  â”œâ”€ classification_codes.csv           # Classification codes data
â”‚  â”‚  â”œâ”€ keywords.csv                       # Keywords data
â”‚  â”‚  â”œâ”€ paper_to_affiliation.csv           # Paper to affiliation data
â”‚  â”‚  â”œâ”€ paper_to_classification_code.csv   # Paper to classification code data
â”‚  â”‚  â”œâ”€ paper_to_keyword.csv               # Paper to keyword data
â”‚  â”‚  â”œâ”€ papers.csv                         # Papers data
â”‚  â”‚  â””â”€ subjects.csv                       # Subjects data
â”‚  â”œâ”€ raw                                   # Raw data
â”‚  â”‚  â”œâ”€ Data 2018-2023                     # Given data from 2018-2023
â”‚  â”‚  |  â””â”€ {year}                          # Yearly data (Ex. 2018)
â”‚  â”‚  |     â””â”€ {year}{number}               # Paper data as CSV (Ex. 201800000)
â”‚  â”‚  â”œâ”€ fetched_papers                     # Fetched papers from 2000-2017
â”‚  â”‚  |  â””â”€ abstract                        # Scopus Abstracts API
â”‚  â”‚  |     â””â”€ {year}                       # Yearly data (Ex. 2000)
â”‚  â”‚  |        â””â”€ {year}-{offset}.json      # Paper data (Ex. 2000-0.json)
â”‚  â”‚  â””â”€ classification_codes_raw.html      # Classification codes data
â”‚  â””â”€ schema                                # Data schema
â”‚     â””â”€ raw_data_schema.json               # Raw data schema of given papers
â”œâ”€ models                                   # Model directory
â”‚  â”œâ”€ multilabel_binarizer.pkl              # Multilabel binarizer
â”‚  â”œâ”€ multilabel_classification_model.pkl   # Multilabel classification model
â”‚  â”œâ”€ pipeline                              # Pipeline directory
â”‚  â”‚  â””â”€ pipeline.pkl                       # Pipeline of the model
â”‚  â”œâ”€ tfidf_vectorizer.pkl                  # TF-IDF vectorizer
â”‚  â””â”€ tokenizer.json                        # Tokenizer
â”œâ”€ notebooks                                # Jupyter notebooks
â”‚  â”œâ”€ 1_data_preparation                    # Data preparation notebooks
â”‚  â”‚  â”œâ”€ data_preparation.ipynb             # Data preparation notebook
â”‚  â”‚  â””â”€ subject_scrape.ipynb               # Subject scraping notebook
â”‚  â”œâ”€ 2_eda                                 # Exploratory data analysis notebooks
â”‚  â”‚  â”œâ”€ eda.ipynb                          # Exploratory data analysis notebook
â”‚  â”‚  â””â”€ eda_streamlit.py                   # Streamlit EDA app
â”‚  â”œâ”€ 3_model_training                      # Model training notebooks
â”‚  â”‚  â””â”€ model_training.ipynb               # Model training notebook
â”‚  â”œâ”€ 4_model_usage                         # Model usage notebooks
â”‚  â”‚  â””â”€ model_usage.ipynb                  # Model usage notebook
â”‚  â””â”€ data_visualization                    # Data visualization resources for the Streamlit app
â”‚     â””â”€ countries.geo.json                 # GeoJSON data for countries
â”œâ”€ requirements.txt                         # The requirements file for the Streamlit app
â”œâ”€ src                                      # Source code directory
â”‚  â””â”€ model                                 # Schema validation model directory
â”‚     â”œâ”€ __init__.py                        # Schema validation model init file
â”‚     â”œâ”€ validation.py                      # Schema validation model
â”‚     â””â”€ validation_test.ipynb              # Schema validation model test notebook
â”œâ”€ utils                                    # Utility directory
â”‚  â”œâ”€ __init__.py                           # Utility init file
â”‚  â”œâ”€ load_pipeline.py                      # Load pipeline utility 
â”‚  â””â”€ utils.py                              # Utility functions
â””â”€ workflow                                 # Prefect workflow directory
   â””â”€ web_scrape.py                         # Prefect web scraping workflow

Â©generated by Project Tree Generator
```

## Setup

1. Move the folder `Data 2018-2023` into the repo